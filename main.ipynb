{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "625004105_hw2.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.8"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FUStugfzWud2"
      },
      "source": [
        "## CSCE 676 :: Data Mining and Analysis :: Texas A&M University :: Fall 2021\n",
        "\n",
        "***Apache PySpark***\n",
        "\n",
        "**There are three objectives:** \n",
        "\n",
        "* Become familiar with Apache Spark\n",
        "* Get hands-on experience using Spark built-in functions; namely, LDA and PageRank\n",
        "* Understand and implement Trawling algorithm to find user communities"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eql4ThhZt5lL"
      },
      "source": [
        "Write your collaboration/references here\n",
        "- https://spark.apache.org/docs/latest/api/python/reference/api/pyspark.sql.DataFrame.html\n",
        "- https://stackoverflow.com/questions/59129462/pyspark-getting-the-most-common-value-of-a-column\n",
        "- https://github.com/alejandronotario/LDA-Topic-Modeling/blob/master/pySpark/LDA_pySpark.ipynb\n",
        "- https://stackoverflow.com/questions/56115833/how-to-get-the-topic-using-pyspark-lda\n",
        "- Dr. Cav's starter code for LDA on Campuswire\n",
        "- https://spark.apache.org/docs/2.3.0/ml-frequent-pattern-mining.html\n",
        "- https://stackoverflow.com/questions/46956026/how-to-convert-column-with-string-type-to-int-form-in-pyspark-data-frame\n",
        "- https://stackoverflow.com/questions/31058504/spark-1-4-increase-maxresultsize-memory\n",
        "- https://stackoverflow.com/questions/55234587/merge-two-column-in-spark-dataframe-to-form-single-column\n",
        "- https://graphframes.github.io/graphframes/docs/_site/quick-start.html"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3AQt_pCoWueB"
      },
      "source": [
        "## Introduction to the Dataset\n",
        "We will use a dataset of tweets concerning members of the US congress. The data spans almost a year (from October 3rd, 2018 to September 25th, 2019) covering 576 of the members. Any tweet or retweet posted by the 576 members or directed to them by other Twitter users were collected.\n",
        "\n",
        "Originally there were more than 200 million tweets collected but we have sampled 400,000 tweets for this homework.\n",
        "\n",
        "Below is a summary of all datasets used for this homework:\n",
        "\n",
        "| Dataset                        | Description |\n",
        "| :---                                                       | :---\n",
        "| Congress members               | 576 twitter ids and screen names |\n",
        "| Sample tweets                  |400k sample tweets|\n",
        "| User hashtags                  | all pairs of <user, hashtag>|\n",
        "| User mentions                  | all pairs of <src_user_id, src_dest_id, frequency> |\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tQ8cZb5cg5Im"
      },
      "source": [
        "Following are the steps that you need to execute to install spark. Remember you need to execute them everytime after your runtime is disconnected"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3xiQ6bMbXITQ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3ccf970f-d6f4-417f-e154-967b37fa043f"
      },
      "source": [
        "!pip install pyspark\n",
        "!pip install graphframes\n",
        "!pip install -U -q PyDrive\n",
        "!apt install openjdk-8-jdk-headless -qq\n",
        "!curl -L -o \"/usr/local/lib/python3.7/dist-packages/pyspark/jars/graphframes-0.8.1-spark3.0-s_2.12.jar\" https://repos.spark-packages.org/graphframes/graphframes/0.8.1-spark3.0-s_2.12/graphframes-0.8.1-spark3.0-s_2.12.jar\n",
        "import os\n",
        "os.environ[\"JAVA_HOME\"] = \"/usr/lib/jvm/java-8-openjdk-amd64\""
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pyspark\n",
            "  Downloading pyspark-3.1.2.tar.gz (212.4 MB)\n",
            "\u001b[K     |████████████████████████████████| 212.4 MB 66 kB/s \n",
            "\u001b[?25hCollecting py4j==0.10.9\n",
            "  Downloading py4j-0.10.9-py2.py3-none-any.whl (198 kB)\n",
            "\u001b[K     |████████████████████████████████| 198 kB 57.1 MB/s \n",
            "\u001b[?25hBuilding wheels for collected packages: pyspark\n",
            "  Building wheel for pyspark (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pyspark: filename=pyspark-3.1.2-py2.py3-none-any.whl size=212880768 sha256=44a67a66e957fa09f715f28c73c5cfe12c5774bb9a9d522a99733a7225849307\n",
            "  Stored in directory: /root/.cache/pip/wheels/a5/0a/c1/9561f6fecb759579a7d863dcd846daaa95f598744e71b02c77\n",
            "Successfully built pyspark\n",
            "Installing collected packages: py4j, pyspark\n",
            "Successfully installed py4j-0.10.9 pyspark-3.1.2\n",
            "Collecting graphframes\n",
            "  Downloading graphframes-0.6-py2.py3-none-any.whl (18 kB)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from graphframes) (1.19.5)\n",
            "Collecting nose\n",
            "  Downloading nose-1.3.7-py3-none-any.whl (154 kB)\n",
            "\u001b[K     |████████████████████████████████| 154 kB 6.3 MB/s \n",
            "\u001b[?25hInstalling collected packages: nose, graphframes\n",
            "Successfully installed graphframes-0.6 nose-1.3.7\n",
            "The following additional packages will be installed:\n",
            "  openjdk-8-jre-headless\n",
            "Suggested packages:\n",
            "  openjdk-8-demo openjdk-8-source libnss-mdns fonts-dejavu-extra\n",
            "  fonts-ipafont-gothic fonts-ipafont-mincho fonts-wqy-microhei\n",
            "  fonts-wqy-zenhei fonts-indic\n",
            "The following NEW packages will be installed:\n",
            "  openjdk-8-jdk-headless openjdk-8-jre-headless\n",
            "0 upgraded, 2 newly installed, 0 to remove and 37 not upgraded.\n",
            "Need to get 36.5 MB of archives.\n",
            "After this operation, 143 MB of additional disk space will be used.\n",
            "Selecting previously unselected package openjdk-8-jre-headless:amd64.\n",
            "(Reading database ... 155047 files and directories currently installed.)\n",
            "Preparing to unpack .../openjdk-8-jre-headless_8u292-b10-0ubuntu1~18.04_amd64.deb ...\n",
            "Unpacking openjdk-8-jre-headless:amd64 (8u292-b10-0ubuntu1~18.04) ...\n",
            "Selecting previously unselected package openjdk-8-jdk-headless:amd64.\n",
            "Preparing to unpack .../openjdk-8-jdk-headless_8u292-b10-0ubuntu1~18.04_amd64.deb ...\n",
            "Unpacking openjdk-8-jdk-headless:amd64 (8u292-b10-0ubuntu1~18.04) ...\n",
            "Setting up openjdk-8-jre-headless:amd64 (8u292-b10-0ubuntu1~18.04) ...\n",
            "update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/jre/bin/orbd to provide /usr/bin/orbd (orbd) in auto mode\n",
            "update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/jre/bin/servertool to provide /usr/bin/servertool (servertool) in auto mode\n",
            "update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/jre/bin/tnameserv to provide /usr/bin/tnameserv (tnameserv) in auto mode\n",
            "Setting up openjdk-8-jdk-headless:amd64 (8u292-b10-0ubuntu1~18.04) ...\n",
            "update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/bin/idlj to provide /usr/bin/idlj (idlj) in auto mode\n",
            "update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/bin/wsimport to provide /usr/bin/wsimport (wsimport) in auto mode\n",
            "update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/bin/jsadebugd to provide /usr/bin/jsadebugd (jsadebugd) in auto mode\n",
            "update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/bin/native2ascii to provide /usr/bin/native2ascii (native2ascii) in auto mode\n",
            "update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/bin/javah to provide /usr/bin/javah (javah) in auto mode\n",
            "update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/bin/hsdb to provide /usr/bin/hsdb (hsdb) in auto mode\n",
            "update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/bin/clhsdb to provide /usr/bin/clhsdb (clhsdb) in auto mode\n",
            "update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/bin/extcheck to provide /usr/bin/extcheck (extcheck) in auto mode\n",
            "update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/bin/schemagen to provide /usr/bin/schemagen (schemagen) in auto mode\n",
            "update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/bin/xjc to provide /usr/bin/xjc (xjc) in auto mode\n",
            "update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/bin/jhat to provide /usr/bin/jhat (jhat) in auto mode\n",
            "update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/bin/wsgen to provide /usr/bin/wsgen (wsgen) in auto mode\n",
            "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
            "                                 Dload  Upload   Total   Spent    Left  Speed\n",
            "100  242k  100  242k    0     0  1044k      0 --:--:-- --:--:-- --:--:-- 1044k\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LHtukwBPl9Nv"
      },
      "source": [
        "The cell below will download the dataset in us-congress-tweets directory"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AWGZu0fZ5Yv9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0163474f-bc82-42bd-82b2-9785023e56a1"
      },
      "source": [
        "!mkdir us-congress-tweets\n",
        "!wget https://us-congress-tweets.s3.amazonaws.com/congress_members.csv -O us-congress-tweets/congress_members.csv\n",
        "!wget https://us-congress-tweets.s3.amazonaws.com/congress-sample-400k.json -O us-congress-tweets/congress-sample-400k.json\n",
        "!wget https://us-congress-tweets.s3.amazonaws.com/user_hashtags-1m.csv -O us-congress-tweets/user_hashtags-1m.csv\n",
        "!wget https://us-congress-tweets.s3.amazonaws.com/user_mentions.csv -O us-congress-tweets/user_mentions.csv"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2021-10-16 17:25:09--  https://us-congress-tweets.s3.amazonaws.com/congress_members.csv\n",
            "Resolving us-congress-tweets.s3.amazonaws.com (us-congress-tweets.s3.amazonaws.com)... 52.217.41.172\n",
            "Connecting to us-congress-tweets.s3.amazonaws.com (us-congress-tweets.s3.amazonaws.com)|52.217.41.172|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 13835 (14K) [text/csv]\n",
            "Saving to: ‘us-congress-tweets/congress_members.csv’\n",
            "\n",
            "us-congress-tweets/ 100%[===================>]  13.51K  --.-KB/s    in 0.03s   \n",
            "\n",
            "2021-10-16 17:25:10 (475 KB/s) - ‘us-congress-tweets/congress_members.csv’ saved [13835/13835]\n",
            "\n",
            "--2021-10-16 17:25:10--  https://us-congress-tweets.s3.amazonaws.com/congress-sample-400k.json\n",
            "Resolving us-congress-tweets.s3.amazonaws.com (us-congress-tweets.s3.amazonaws.com)... 52.217.41.172\n",
            "Connecting to us-congress-tweets.s3.amazonaws.com (us-congress-tweets.s3.amazonaws.com)|52.217.41.172|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 202495914 (193M) [application/json]\n",
            "Saving to: ‘us-congress-tweets/congress-sample-400k.json’\n",
            "\n",
            "us-congress-tweets/ 100%[===================>] 193.11M  68.8MB/s    in 2.8s    \n",
            "\n",
            "2021-10-16 17:25:13 (68.8 MB/s) - ‘us-congress-tweets/congress-sample-400k.json’ saved [202495914/202495914]\n",
            "\n",
            "--2021-10-16 17:25:13--  https://us-congress-tweets.s3.amazonaws.com/user_hashtags-1m.csv\n",
            "Resolving us-congress-tweets.s3.amazonaws.com (us-congress-tweets.s3.amazonaws.com)... 52.216.106.204\n",
            "Connecting to us-congress-tweets.s3.amazonaws.com (us-congress-tweets.s3.amazonaws.com)|52.216.106.204|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 25248825 (24M) [text/csv]\n",
            "Saving to: ‘us-congress-tweets/user_hashtags-1m.csv’\n",
            "\n",
            "us-congress-tweets/ 100%[===================>]  24.08M  46.6MB/s    in 0.5s    \n",
            "\n",
            "2021-10-16 17:25:13 (46.6 MB/s) - ‘us-congress-tweets/user_hashtags-1m.csv’ saved [25248825/25248825]\n",
            "\n",
            "--2021-10-16 17:25:14--  https://us-congress-tweets.s3.amazonaws.com/user_mentions.csv\n",
            "Resolving us-congress-tweets.s3.amazonaws.com (us-congress-tweets.s3.amazonaws.com)... 52.216.106.204\n",
            "Connecting to us-congress-tweets.s3.amazonaws.com (us-congress-tweets.s3.amazonaws.com)|52.216.106.204|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 56152064 (54M) [text/csv]\n",
            "Saving to: ‘us-congress-tweets/user_mentions.csv’\n",
            "\n",
            "us-congress-tweets/ 100%[===================>]  53.55M  65.8MB/s    in 0.8s    \n",
            "\n",
            "2021-10-16 17:25:15 (65.8 MB/s) - ‘us-congress-tweets/user_mentions.csv’ saved [56152064/56152064]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bWOQNZBaXPgs"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "\n",
        "import pyspark\n",
        "from pyspark.sql import *\n",
        "from pyspark.sql.types import *\n",
        "from pyspark import SparkContext, SparkConf"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FG8qQdgRXViL"
      },
      "source": [
        "# create the session\n",
        "conf = SparkConf().set(\"spark.ui.port\", \"4050\").set(\"spark.driver.memory\", \"3g\").set(\"spark.executor.memory\", \"3g\")\n",
        "\n",
        "# create the context\n",
        "sc = pyspark.SparkContext(conf=conf)\n",
        "spark = SparkSession.builder.getOrCreate()\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gmF4bC0P7aut"
      },
      "source": [
        "Now we need to setup ngrok so that we can view spark UI even if its hosted on Google colab's runtime. Please go to https://dashboard.ngrok.com/login, create an account and get the authtoken and replace 'XXXXX' with the auth token for your user. You can also comment that line out to create a temporary tunnel, but it expires soon and won't you use spark monitor further."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6gdr2Pxt7UDN",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "831f7868-6b47-4ca8-835a-391f34cf62a6"
      },
      "source": [
        "!wget https://bin.equinox.io/c/4VmDzA7iaHb/ngrok-stable-linux-amd64.zip\n",
        "!unzip ngrok-stable-linux-amd64.zip"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2021-10-16 17:25:20--  https://bin.equinox.io/c/4VmDzA7iaHb/ngrok-stable-linux-amd64.zip\n",
            "Resolving bin.equinox.io (bin.equinox.io)... 54.161.241.46, 54.237.133.81, 52.202.168.65, ...\n",
            "Connecting to bin.equinox.io (bin.equinox.io)|54.161.241.46|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 13832437 (13M) [application/octet-stream]\n",
            "Saving to: ‘ngrok-stable-linux-amd64.zip’\n",
            "\n",
            "ngrok-stable-linux- 100%[===================>]  13.19M  33.4MB/s    in 0.4s    \n",
            "\n",
            "2021-10-16 17:25:20 (33.4 MB/s) - ‘ngrok-stable-linux-amd64.zip’ saved [13832437/13832437]\n",
            "\n",
            "Archive:  ngrok-stable-linux-amd64.zip\n",
            "  inflating: ngrok                   \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DwvWvr7Y7Zk5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "02ee47ee-b5e9-4e85-c89f-bae5b10fdaa6"
      },
      "source": [
        "get_ipython().system_raw('./ngrok http 4050 &')\n",
        "!./ngrok authtoken 1z0V1FwU9b723YEcUjxOg3Y1FHm_7fFGsSKJP3ER4wug6Etzd\n",
        "!curl -s http://localhost:4040/api/tunnels | python3 -c \"import sys, json; print(json.load(sys.stdin)['tunnels'][0]['public_url'])\""
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Authtoken saved to configuration file: /root/.ngrok2/ngrok.yml\n",
            "https://fae9-35-222-84-146.ngrok.io\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h6qAn1XJWueC",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4667678f-e060-48d2-ee14-9ab7e879d9bf"
      },
      "source": [
        "# First let's read Twitter ids and screen names of the 576 US congress members\n",
        "\n",
        "congress_members = spark.read.csv(\"us-congress-tweets/congress_members.csv\", header=True)\n",
        "congress_members.show()\n",
        "print(\"Number of congress members tracked:\", congress_members.count())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+------------------+---------------+\n",
            "|            userid|    screen_name|\n",
            "+------------------+---------------+\n",
            "|         776664410|  RepCartwright|\n",
            "|         240363117|   RepTomMarino|\n",
            "|837722935095930883| RepScottTaylor|\n",
            "|        1069124515|     RepLaMalfa|\n",
            "|818460870573441028|  RepTomGarrett|\n",
            "|         163570705|     repcleaver|\n",
            "|          19739126|      GOPLeader|\n",
            "|          33563161| RepJoseSerrano|\n",
            "|        2861616083|USRepGaryPalmer|\n",
            "|        1074518754| SenatorBaldwin|\n",
            "|         305620929|  Call_Me_Dutch|\n",
            "|         381152398| RepTerriSewell|\n",
            "|         834069080| RepDavidRouzer|\n",
            "|         249787913|  SenatorCarper|\n",
            "|         188019606|        Clyburn|\n",
            "|         217543151|SenatorTimScott|\n",
            "|          39249305| USRepMikeDoyle|\n",
            "|          33537967|   amyklobuchar|\n",
            "|         249410485|  SanfordBishop|\n",
            "|          23124635|    TomColeOK04|\n",
            "+------------------+---------------+\n",
            "only showing top 20 rows\n",
            "\n",
            "Number of congress members tracked: 576\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eOfjGbB6WueF"
      },
      "source": [
        "We can use `spark.read.json(...)` without schema to load the tweets into a dataframe but this will be slow for two reasons:\n",
        "* First, it will make one pass over the data to build a schema of the content, then a second pass to read the content and parse it to the dataframe. \n",
        "* It will read all the content of the Tweet JSON objects but we only need few fields for a given task.\n",
        "\n",
        "Thus we define our own schema something like the following:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JLBnQUluWueG"
      },
      "source": [
        "from pyspark.sql.types import *\n",
        "import pyspark.sql.functions as F\n",
        "\n",
        "user_schema = StructType([\n",
        "    StructField('created_at',StringType(),True),\n",
        "    StructField('followers_count',LongType(),True),\n",
        "    StructField('id',LongType(),True),\n",
        "    StructField('name',StringType(),True),\n",
        "    StructField('screen_name',StringType(),True)\n",
        "])\n",
        "\n",
        "hashtag_schema = ArrayType(StructType([StructField('text',StringType(),True)]))\n",
        "user_mentions_schema = ArrayType(StructType([StructField('id',LongType(),True),\n",
        "                                             StructField('screen_name',StringType(),True)]))\n",
        "entities_schema = StructType([\n",
        "    StructField('hashtags',hashtag_schema,True),\n",
        "    StructField('user_mentions',user_mentions_schema,True)\n",
        "    ])\n",
        "\n",
        "retweeted_status_schema =StructType([        \n",
        "        StructField(\"id\", LongType(), True),\n",
        "        StructField(\"in_reply_to_user_id\", LongType(), True),\n",
        "        StructField(\"in_reply_to_status_id\", LongType(), True),\n",
        "        StructField(\"created_at\", TimestampType(), True),\n",
        "        StructField(\"user\", user_schema)\n",
        "    ])\n",
        "\n",
        "tweet_schema =StructType([\n",
        "        StructField(\"text\", StringType(), True),\n",
        "        StructField(\"id\", LongType(), True),\n",
        "        StructField(\"in_reply_to_user_id\", LongType(), True),\n",
        "        StructField(\"in_reply_to_status_id\", LongType(), True),\n",
        "        StructField(\"created_at\", StringType(), True),\n",
        "        StructField(\"user\", user_schema),\n",
        "        StructField(\"entities\", entities_schema),\n",
        "        StructField(\"retweeted_status\", retweeted_status_schema)\n",
        "    ])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i6xAE5NXWueH"
      },
      "source": [
        "Now we are ready to read the tweets with `spark.read.json` passing our own schema as follows:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QZa4FIDAWueH",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ad62964e-e240-4c3c-95de-5aa490e8d6d8"
      },
      "source": [
        "tweets = spark.read\\\n",
        "                   .json('us-congress-tweets/congress-sample-400k.json', tweet_schema)\\\n",
        "                   .withColumn('user_id',F.col('user.id'))\n",
        "tweets.printSchema()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "root\n",
            " |-- text: string (nullable = true)\n",
            " |-- id: long (nullable = true)\n",
            " |-- in_reply_to_user_id: long (nullable = true)\n",
            " |-- in_reply_to_status_id: long (nullable = true)\n",
            " |-- created_at: string (nullable = true)\n",
            " |-- user: struct (nullable = true)\n",
            " |    |-- created_at: string (nullable = true)\n",
            " |    |-- followers_count: long (nullable = true)\n",
            " |    |-- id: long (nullable = true)\n",
            " |    |-- name: string (nullable = true)\n",
            " |    |-- screen_name: string (nullable = true)\n",
            " |-- entities: struct (nullable = true)\n",
            " |    |-- hashtags: array (nullable = true)\n",
            " |    |    |-- element: struct (containsNull = true)\n",
            " |    |    |    |-- text: string (nullable = true)\n",
            " |    |-- user_mentions: array (nullable = true)\n",
            " |    |    |-- element: struct (containsNull = true)\n",
            " |    |    |    |-- id: long (nullable = true)\n",
            " |    |    |    |-- screen_name: string (nullable = true)\n",
            " |-- retweeted_status: struct (nullable = true)\n",
            " |    |-- id: long (nullable = true)\n",
            " |    |-- in_reply_to_user_id: long (nullable = true)\n",
            " |    |-- in_reply_to_status_id: long (nullable = true)\n",
            " |    |-- created_at: timestamp (nullable = true)\n",
            " |    |-- user: struct (nullable = true)\n",
            " |    |    |-- created_at: string (nullable = true)\n",
            " |    |    |-- followers_count: long (nullable = true)\n",
            " |    |    |-- id: long (nullable = true)\n",
            " |    |    |-- name: string (nullable = true)\n",
            " |    |    |-- screen_name: string (nullable = true)\n",
            " |-- user_id: long (nullable = true)\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HyAc0ou-WueI"
      },
      "source": [
        "## (10 points) Part 1: Exploratory Data Analysis (Small Scale)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EFo2xXh1WueI"
      },
      "source": [
        "How many unique users and original tweets (i.e. not retweets) are there? "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BsOKUUR_7X3w",
        "outputId": "ffca70a0-4275-4ce7-bbd4-c918f0620c13"
      },
      "source": [
        "tweets.head(10)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[Row(text='RT @maddow: \"I hear a lot about about lack of corroboration. You know, you don\\'t get corroboration if you don\\'t talk to corroborating witne…', id=1047999818038050816, in_reply_to_user_id=None, in_reply_to_status_id=None, created_at='2018-10-05T00:00:02.000Z', user=Row(created_at='2017-03-22T03:11:54.000Z', followers_count=527, id=844386122822119424, name='Quazy', screen_name='quazy101'), entities=Row(hashtags=[], user_mentions=[Row(id=16129920, screen_name='maddow')]), retweeted_status=Row(id=1047941326975766530, in_reply_to_user_id=None, in_reply_to_status_id=None, created_at=datetime.datetime(2018, 10, 4, 20, 7, 36), user=Row(created_at='2008-09-04T15:02:12.000Z', followers_count=9503143, id=16129920, name='Rachel Maddow MSNBC', screen_name='maddow')), user_id=844386122822119424),\n",
              " Row(text=\"@ChuckGrassley @SenateMajLdr It's time for you to leave Congress &amp; let the country heal from all of the damage you'… https://t.co/ncaQg3nisb\", id=1047999818579292160, in_reply_to_user_id=10615232, in_reply_to_status_id=None, created_at='2018-10-05T00:00:02.000Z', user=Row(created_at='2016-01-29T01:49:38.000Z', followers_count=73, id=4828166688, name='cookiesparadiso', screen_name='sparadiso11'), entities=Row(hashtags=[], user_mentions=[Row(id=10615232, screen_name='ChuckGrassley'), Row(id=1249982359, screen_name='senatemajldr')]), retweeted_status=None, user_id=4828166688),\n",
              " Row(text='RT @cm_merlin: @funder @JeffFlake @lisamurkowski @SenatorCollins Kavanaugh disqualified himself with perjury &amp; bias. \\nThe entire world saw…', id=1048000082237247488, in_reply_to_user_id=None, in_reply_to_status_id=None, created_at='2018-10-05T00:01:05.000Z', user=Row(created_at='2016-09-10T05:42:53.000Z', followers_count=12449, id=774483262693527553, name='putins_puppet', screen_name='disqualify_gop'), entities=Row(hashtags=[], user_mentions=[Row(id=28241597, screen_name='cm_merlin'), Row(id=14247236, screen_name='funder'), Row(id=16056306, screen_name='JeffFlake'), Row(id=18061669, screen_name='lisamurkowski'), Row(id=19726613, screen_name='SenatorCollins')]), retweeted_status=Row(id=1047988201678286848, in_reply_to_user_id=14247236, in_reply_to_status_id=1047961775604473856, created_at=datetime.datetime(2018, 10, 4, 23, 13, 52), user=Row(created_at='2009-04-02T00:52:17.000Z', followers_count=2343, id=28241597, name='Chris Morris', screen_name='cm_merlin')), user_id=774483262693527553),\n",
              " Row(text='RT @SenJeffMerkley: I read the FBI report.  This whole thing is a sham.  This stunted, strangled investigation was designed to provide cove…', id=1048000473037524993, in_reply_to_user_id=None, in_reply_to_status_id=None, created_at='2018-10-05T00:02:38.000Z', user=Row(created_at='2012-11-17T11:39:10.000Z', followers_count=578, id=953411978, name='cmhorton', screen_name='c_millerhorton'), entities=Row(hashtags=[], user_mentions=[Row(id=29201047, screen_name='SenJeffMerkley')]), retweeted_status=Row(id=1047893222859534336, in_reply_to_user_id=None, in_reply_to_status_id=None, created_at=datetime.datetime(2018, 10, 4, 16, 56, 27), user=Row(created_at='2009-04-06T13:38:39.000Z', followers_count=409403, id=29201047, name='Senator Jeff Merkley', screen_name='SenJeffMerkley')), user_id=953411978),\n",
              " Row(text='RT @SenJeffMerkley: I read the FBI report.  This whole thing is a sham.  This stunted, strangled investigation was designed to provide cove…', id=1048000484429189122, in_reply_to_user_id=None, in_reply_to_status_id=None, created_at='2018-10-05T00:02:41.000Z', user=Row(created_at='2009-01-19T12:16:31.000Z', followers_count=489, id=19181136, name='Philipsgma', screen_name='philipsgma'), entities=Row(hashtags=[], user_mentions=[Row(id=29201047, screen_name='SenJeffMerkley')]), retweeted_status=Row(id=1047893222859534336, in_reply_to_user_id=None, in_reply_to_status_id=None, created_at=datetime.datetime(2018, 10, 4, 16, 56, 27), user=Row(created_at='2009-04-06T13:38:39.000Z', followers_count=409403, id=29201047, name='Senator Jeff Merkley', screen_name='SenJeffMerkley')), user_id=19181136),\n",
              " Row(text=\"RT @SenDuckworth: Brett Kavanaugh's steady stream of lies and angry partisan tirades should be disqualifying. I delivered a speech from the…\", id=1048000750700388353, in_reply_to_user_id=None, in_reply_to_status_id=None, created_at='2018-10-05T00:03:44.000Z', user=Row(created_at='2013-08-12T15:50:06.000Z', followers_count=147, id=1665358626, name='RobertJ25', screen_name='RobertJ14398206'), entities=Row(hashtags=[], user_mentions=[Row(id=1058520120, screen_name='SenDuckworth')]), retweeted_status=Row(id=1047940472319234048, in_reply_to_user_id=None, in_reply_to_status_id=None, created_at=datetime.datetime(2018, 10, 4, 20, 4, 13), user=Row(created_at='2013-01-03T18:59:33.000Z', followers_count=504929, id=1058520120, name='Tammy Duckworth', screen_name='SenDuckworth')), user_id=1665358626),\n",
              " Row(text='RT @SenSchumer: After reviewing the additional background check documents on Judge Kavanaugh, four things are crystal clear.\\n\\nFirst, the do…', id=1048001191857332224, in_reply_to_user_id=None, in_reply_to_status_id=None, created_at='2018-10-05T00:05:29.000Z', user=Row(created_at='2016-09-16T00:55:42.000Z', followers_count=713, id=776585315796520964, name='Wendy Sue Verran', screen_name='WendyVerran'), entities=Row(hashtags=[], user_mentions=[Row(id=17494010, screen_name='SenSchumer')]), retweeted_status=Row(id=1047947859193159682, in_reply_to_user_id=None, in_reply_to_status_id=None, created_at=datetime.datetime(2018, 10, 4, 20, 33, 34), user=Row(created_at='2008-11-19T20:10:20.000Z', followers_count=1510278, id=17494010, name='Chuck Schumer', screen_name='SenSchumer')), user_id=776585315796520964),\n",
              " Row(text='Kavanaugh -cry me an F-ing River! Your temperament is one thing, but your lying under oath &amp; partisan stance made f… https://t.co/zoXXElKUTQ', id=1048001205253931013, in_reply_to_user_id=None, in_reply_to_status_id=None, created_at='2018-10-05T00:05:32.000Z', user=Row(created_at='2016-07-21T03:18:52.000Z', followers_count=2274, id=755965235698163712, name='JBeckner_US Patriot 🇺🇸🧢🌊', screen_name='Jbeckner121105'), entities=Row(hashtags=[], user_mentions=[]), retweeted_status=None, user_id=755965235698163712),\n",
              " Row(text='My only hope is in God. All these corrupt republicans will have to face the only true judge come judgment day.  Gre… https://t.co/0UhvqKy77s', id=1048001311315283970, in_reply_to_user_id=None, in_reply_to_status_id=None, created_at='2018-10-05T00:05:58.000Z', user=Row(created_at='2017-10-18T19:47:34.000Z', followers_count=91, id=920738142151434240, name='Cindy Minor', screen_name='faithofthehrt6'), entities=Row(hashtags=[], user_mentions=[]), retweeted_status=None, user_id=920738142151434240),\n",
              " Row(text='@Cain3707 @sween06103 @OakieEd @kmm01880 @elainaplott @JeffFlake Shhhh, the grown ups are arguing.', id=1048001436242665472, in_reply_to_user_id=248050894, in_reply_to_status_id=1047952882002096128, created_at='2018-10-05T00:06:27.000Z', user=Row(created_at='2014-11-21T10:15:55.000Z', followers_count=98, id=2886735226, name='Stephen_James_Norton', screen_name='TimperleySunset'), entities=Row(hashtags=[], user_mentions=[Row(id=248050894, screen_name='Cain3707'), Row(id=2737925552, screen_name='sween06103'), Row(id=50101827, screen_name='OakieEd'), Row(id=1045014133492645889, screen_name='kmm01880'), Row(id=42153941, screen_name='elainaplott'), Row(id=16056306, screen_name='JeffFlake')]), retweeted_status=None, user_id=2886735226)]"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RZJGG4bzWueK",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c956e370-c23b-493b-f696-a6a2cde5c4b9"
      },
      "source": [
        "#ANSWER\n",
        "# your code here for unique users\n",
        "\"\"\"\n",
        "Steps: I select the user id column, drop all duplicates, and then get a total count\n",
        "\"\"\"\n",
        "unique_users = tweets.select('user_id').distinct().count()\n",
        "print(\"Unique Users Count = \", unique_users)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Unique Users Count =  198098\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zoq27DCqWueL",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ffe99c78-9079-4cad-cd18-9c64f35631e5"
      },
      "source": [
        "#ANSWER\n",
        "# your code here for original tweets\n",
        "\"\"\"\n",
        "Steps: same process as above but with Tweet IDs. Here I am also dropping all retweeted status = NaN/Null\n",
        "\"\"\"\n",
        "unique_tweets = tweets.select('id').where(tweets.retweeted_status.isNull()).count()\n",
        "print(\"Original Tweets Count = \", unique_tweets)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Original Tweets Count =  210753\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zY5_nDCCWueM"
      },
      "source": [
        "Who are the ten most mentioned users in the sample?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YrkN__kuWueM",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "04bc2a29-d549-472c-81c7-cbf7b71e8b45"
      },
      "source": [
        "#ANSWER\n",
        "# code here\n",
        "\"\"\"\n",
        "Steps:\n",
        "1) use explode function to 'singularize' the multi row columns in screen name\n",
        "2) get count of each screen name and store it in count\n",
        "3) order the dataframe by count to view the top 10\n",
        "\"\"\"\n",
        "from pyspark.sql.functions import desc, explode\n",
        "\n",
        "exploded_mentions = tweets.select(explode(tweets.entities.user_mentions.screen_name).alias('screen_names'))\n",
        "most_mentioned_users = exploded_mentions.groupBy('screen_names').count()\n",
        "most_mentioned_users.orderBy(desc('count')).show(10)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---------------+-----+\n",
            "|   screen_names|count|\n",
            "+---------------+-----+\n",
            "|realDonaldTrump|24522|\n",
            "|   senatemajldr|15021|\n",
            "|LindseyGrahamSC|14412|\n",
            "|     SenSchumer|13738|\n",
            "|  RepAdamSchiff|13288|\n",
            "|  SpeakerPelosi|12478|\n",
            "|     marcorubio| 9957|\n",
            "|     Jim_Jordan| 9453|\n",
            "|     SenSanders| 6861|\n",
            "|    RepSwalwell| 6224|\n",
            "+---------------+-----+\n",
            "only showing top 10 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BIwGhG_OWueN"
      },
      "source": [
        "What are the top hashtags used?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fztHxTpyWueN",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9d2ed324-c732-48a8-d1c9-23ee6000f670"
      },
      "source": [
        "#ANSWER\n",
        "# code here\n",
        "\"\"\"\n",
        "Steps: same process as above but with hashtags\n",
        "\"\"\"\n",
        "exploded_hashtags = tweets.select(explode(tweets.entities.hashtags).alias('hashtags'))\n",
        "most_mentioned_hashtags = exploded_hashtags.groupBy('hashtags').count()\n",
        "most_mentioned_hashtags.orderBy(desc('count')).show(10)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---------------+-----+\n",
            "|       hashtags|count|\n",
            "+---------------+-----+\n",
            "|    {Venezuela}| 1224|\n",
            "|  {MoscowMitch}| 1123|\n",
            "|{TrumpShutdown}|  705|\n",
            "|         {MAGA}|  535|\n",
            "|{MuellerReport}|  396|\n",
            "|  {NancyPelosi}|  349|\n",
            "| {MaduroRegime}|  347|\n",
            "|        {Trump}|  338|\n",
            "| {BuildTheWall}|  333|\n",
            "| {GreenNewDeal}|  297|\n",
            "+---------------+-----+\n",
            "only showing top 10 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FYLSNhTgWueR"
      },
      "source": [
        "## (25 points) Part 2: Textual Analysis (LDA)\n",
        "Using the LDA algorithm provided by the Spark Machine Learning (ML) library, find out the ten most important topics.\n",
        "\n",
        "You may want to work on a small sample first but report your results on the whole dataset.\n",
        "\n",
        "Hint:\n",
        "\n",
        " 1) For better results aggregate all tweets for a user into a single document\n",
        "\n",
        "2) For debugging sample 10% of the tweets, but at the end report your results on entire dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kDY9C-k3h_SE"
      },
      "source": [
        "from pyspark.sql.functions import *\n",
        "from pyspark.ml.feature import * \n",
        "from pyspark.ml.clustering import LDA, LDAModel\n",
        "from pyspark.sql import SQLContext"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sL-IvJs1WueR"
      },
      "source": [
        "# your code here\n",
        "# HINT - Aggregate tweets together based on user IDs and create a new column. On that new column, use preprocessing/cleaning techniuqes (stop word, removal, lower case, tf-idf, etc.), and use LDA.\n",
        "\n",
        "\"\"\"\n",
        "1) Originally, for debugging purposes, only 10% of tweets are sampled. Later 100% was used.\n",
        "2) First, a new dataframe 'user_document' is created with id and their respective aggregated texts\n",
        "3) remove punctuation function is applied to remove redundant characters\n",
        "4) words are then tokenized into individual objects in array\n",
        "5) StopWordsRemover function is used to further filter the document\n",
        "\"\"\"\n",
        "\n",
        "# Function to remove punctuations\n",
        "def removePunctuation(column):\n",
        "    return trim(lower(regexp_replace(column, '[^\\s@a-zA-Z0-9]', ''))).alias(\"document\")\n",
        "\n",
        "# Sample 100% of the tweets\n",
        "sampled_tweets = tweets   # .sample(False, 0.1, 42)\n",
        "\n",
        "# Concat all tweets from a user and create tweet documents\n",
        "user_document = sampled_tweets.groupby(\"user.id\").agg(F.concat_ws(\" \", F.collect_list(\"text\")).alias(\"document\"))\n",
        "\n",
        "# Remove punctuation marks from the tweets\n",
        "user_document = user_document.select(\"id\", removePunctuation(F.col(\"document\")))\n",
        "\n",
        "# Tokenize to obtain words from tweets\n",
        "tokenizer = Tokenizer(inputCol=\"document\", outputCol=\"words\")\n",
        "wordsDataFrame = tokenizer.transform(user_document)\n",
        "\n",
        "# Remove stopwords\n",
        "remover = StopWordsRemover(inputCol=\"words\", outputCol=\"filtered\")\n",
        "wordsDataFrame = remover.transform(wordsDataFrame)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Kmc-3MqqY2UB",
        "outputId": "a2abbf8e-df0b-44ff-a331-e4bad817d1e9"
      },
      "source": [
        "# TODO - build CountVectorizer, TF-IDF vectors, run LDA\n",
        "wordsDataFrame.show()\n",
        "user_document.take(5)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------+--------------------+--------------------+--------------------+\n",
            "|      id|            document|               words|            filtered|\n",
            "+--------+--------------------+--------------------+--------------------+\n",
            "|  820694|@jennycohn1 @ronw...|[@jennycohn1, @ro...|[@jennycohn1, @ro...|\n",
            "| 5385802|rt @chrismurphyct...|[rt, @chrismurphy...|[rt, @chrismurphy...|\n",
            "|12953952|rt @magagwen @rep...|[rt, @magagwen, @...|[rt, @magagwen, @...|\n",
            "|13290282|you folks have pr...|[you, folks, have...|[folks, proven, l...|\n",
            "|13492362|rt @comradezaco r...|[rt, @comradezaco...|[rt, @comradezaco...|\n",
            "|14060717|next week 2020 de...|[next, week, 2020...|[next, week, 2020...|\n",
            "|14555541|rt @kim @repadams...|[rt, @kim, @repad...|[rt, @kim, @repad...|\n",
            "|14883391|rt @4evernevertru...|[rt, @4evernevert...|[rt, @4evernevert...|\n",
            "|14884712|@reptedlieu keeps...|[@reptedlieu, kee...|[@reptedlieu, kee...|\n",
            "|15197290|rt @kylegriffin1 ...|[rt, @kylegriffin...|[rt, @kylegriffin...|\n",
            "|15261298|rt @billclarkphot...|[rt, @billclarkph...|[rt, @billclarkph...|\n",
            "|15416371|rt @speakerpelosi...|[rt, @speakerpelo...|[rt, @speakerpelo...|\n",
            "|15541045|                    |                  []|                  []|\n",
            "|15651137|rt @nancypelosi w...|[rt, @nancypelosi...|[rt, @nancypelosi...|\n",
            "|15743275|rt @mattduss chen...|[rt, @mattduss, c...|[rt, @mattduss, c...|\n",
            "|16372633|rt @chrismurphyct...|[rt, @chrismurphy...|[rt, @chrismurphy...|\n",
            "|16440115|rt @justinamash w...|[rt, @justinamash...|[rt, @justinamash...|\n",
            "|16565600|@atticemphatic @c...|[@atticemphatic, ...|[@atticemphatic, ...|\n",
            "|16913193|rt @charliekirk11...|[rt, @charliekirk...|[rt, @charliekirk...|\n",
            "|17163957|@senbobcasey in t...|[@senbobcasey, in...|[@senbobcasey, po...|\n",
            "+--------+--------------------+--------------------+--------------------+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[Row(id=820694, document='@jennycohn1 @ronwyden thiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiis rt @blogdiva @speakerpelosi democrats against\\nimpeachmenthearingsnow \\n\\n1 @repcummings \\n2 @adamschiff \\n3 @reprichardneal\\n4 @speakerpel rt @hansilowang just in chair of house appropriations subcommittee that funds 2020census @repjoseserrano dny says hes been diagnos'),\n",
              " Row(id=5385802, document='rt @chrismurphyct november is coming httpstcoeroueiu67j rt @epluribusunumep @greenjeanasset @firni @senatemajldr @gop @potus definitely not an anaconda hes a   shitviper rt @smunk8munk @bettynjackson @firni @chrismurphyct @amandablount2 installed by putin to cause helter skelter  working out perfectly lo'),\n",
              " Row(id=12953952, document='rt @magagwen @repmarkmeadows there is information coming that will curl your hair  adam schiff has seen documents that he knows wil'),\n",
              " Row(id=13290282, document='you folks have proven yourselves to be liars cheaters amp thieves if youd learn how to use your brains you could httpstcod8tjd1i37a'),\n",
              " Row(id=13492362, document='rt @comradezaco reminds me of this alistar james dude started as a hotelier then a hunting company in ruaha now dudes runs a transport co')]"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iFUtunS60BBs"
      },
      "source": [
        "\"\"\"\n",
        "Steps: use count vectorizer to get token count matrix as 'raw_features'\n",
        "\"\"\"\n",
        "cv = CountVectorizer(inputCol='filtered', outputCol='raw_features', vocabSize=20000, minDF=10.0)\n",
        "cvmodel = cv.fit(wordsDataFrame)\n",
        "result_cv = cvmodel.transform(wordsDataFrame)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Nrj04WMv1Hs3",
        "outputId": "3813711f-d8a9-4d48-b915-29502c0d3ab2"
      },
      "source": [
        "\"\"\"\n",
        "Steps use idf to get word importance from raw features into new 'features' column\n",
        "\"\"\"\n",
        "idf = IDF(inputCol='raw_features', outputCol='features')\n",
        "idfmodel = idf.fit(result_cv)\n",
        "result_tfidf = idfmodel.transform(result_cv)\n",
        "result_tfidf.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
            "|      id|            document|               words|            filtered|        raw_features|            features|\n",
            "+--------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
            "|  820694|@jennycohn1 @ronw...|[@jennycohn1, @ro...|[@jennycohn1, @ro...|(20000,[0,1,10,18...|(20000,[0,1,10,18...|\n",
            "| 5385802|rt @chrismurphyct...|[rt, @chrismurphy...|[rt, @chrismurphy...|(20000,[0,1,5,40,...|(20000,[0,1,5,40,...|\n",
            "|12953952|rt @magagwen @rep...|[rt, @magagwen, @...|[rt, @magagwen, @...|(20000,[0,1,43,37...|(20000,[0,1,43,37...|\n",
            "|13290282|you folks have pr...|[you, folks, have...|[folks, proven, l...|(20000,[4,205,913...|(20000,[4,205,913...|\n",
            "|13492362|rt @comradezaco r...|[rt, @comradezaco...|[rt, @comradezaco...|(20000,[0,32,568,...|(20000,[0,32,568,...|\n",
            "|14060717|next week 2020 de...|[next, week, 2020...|[next, week, 2020...|(20000,[92,119,18...|(20000,[92,119,18...|\n",
            "|14555541|rt @kim @repadams...|[rt, @kim, @repad...|[rt, @kim, @repad...|(20000,[0,1,9,842...|(20000,[0,1,9,842...|\n",
            "|14883391|rt @4evernevertru...|[rt, @4evernevert...|[rt, @4evernevert...|(20000,[0,3,57,13...|(20000,[0,3,57,13...|\n",
            "|14884712|@reptedlieu keeps...|[@reptedlieu, kee...|[@reptedlieu, kee...|(20000,[37,158,50...|(20000,[37,158,50...|\n",
            "|15197290|rt @kylegriffin1 ...|[rt, @kylegriffin...|[rt, @kylegriffin...|(20000,[0,223,243...|(20000,[0,223,243...|\n",
            "|15261298|rt @billclarkphot...|[rt, @billclarkph...|[rt, @billclarkph...|(20000,[0,25,144,...|(20000,[0,25,144,...|\n",
            "|15416371|rt @speakerpelosi...|[rt, @speakerpelo...|[rt, @speakerpelo...|(20000,[0,2,10,19...|(20000,[0,2,10,19...|\n",
            "|15541045|                    |                  []|                  []|   (20000,[1],[1.0])|(20000,[1],[1.075...|\n",
            "|15651137|rt @nancypelosi w...|[rt, @nancypelosi...|[rt, @nancypelosi...|(20000,[0,4,23,59...|(20000,[0,4,23,59...|\n",
            "|15743275|rt @mattduss chen...|[rt, @mattduss, c...|[rt, @mattduss, c...|(20000,[0,20,47,6...|(20000,[0,20,47,6...|\n",
            "|16372633|rt @chrismurphyct...|[rt, @chrismurphy...|[rt, @chrismurphy...|(20000,[0,7,17,45...|(20000,[0,7,17,45...|\n",
            "|16440115|rt @justinamash w...|[rt, @justinamash...|[rt, @justinamash...|(20000,[0,2,14,23...|(20000,[0,2,14,23...|\n",
            "|16565600|@atticemphatic @c...|[@atticemphatic, ...|[@atticemphatic, ...|(20000,[97,1683,1...|(20000,[97,1683,1...|\n",
            "|16913193|rt @charliekirk11...|[rt, @charliekirk...|[rt, @charliekirk...|(20000,[0,1,18,66...|(20000,[0,1,18,66...|\n",
            "|17163957|@senbobcasey in t...|[@senbobcasey, in...|[@senbobcasey, po...|(20000,[11,333,56...|(20000,[11,333,56...|\n",
            "+--------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9vFjLN8W4umQ",
        "outputId": "1953fa17-0d65-4810-d141-050adfd16246"
      },
      "source": [
        "df_model = result_tfidf.select('id', 'filtered', 'features')\n",
        "df_model.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------+--------------------+--------------------+\n",
            "|      id|            filtered|            features|\n",
            "+--------+--------------------+--------------------+\n",
            "|  820694|[@jennycohn1, @ro...|(20000,[0,1,10,18...|\n",
            "| 5385802|[rt, @chrismurphy...|(20000,[0,1,5,40,...|\n",
            "|12953952|[rt, @magagwen, @...|(20000,[0,1,43,37...|\n",
            "|13290282|[folks, proven, l...|(20000,[4,205,913...|\n",
            "|13492362|[rt, @comradezaco...|(20000,[0,32,568,...|\n",
            "|14060717|[next, week, 2020...|(20000,[92,119,18...|\n",
            "|14555541|[rt, @kim, @repad...|(20000,[0,1,9,842...|\n",
            "|14883391|[rt, @4evernevert...|(20000,[0,3,57,13...|\n",
            "|14884712|[@reptedlieu, kee...|(20000,[37,158,50...|\n",
            "|15197290|[rt, @kylegriffin...|(20000,[0,223,243...|\n",
            "|15261298|[rt, @billclarkph...|(20000,[0,25,144,...|\n",
            "|15416371|[rt, @speakerpelo...|(20000,[0,2,10,19...|\n",
            "|15541045|                  []|(20000,[1],[1.075...|\n",
            "|15651137|[rt, @nancypelosi...|(20000,[0,4,23,59...|\n",
            "|15743275|[rt, @mattduss, c...|(20000,[0,20,47,6...|\n",
            "|16372633|[rt, @chrismurphy...|(20000,[0,7,17,45...|\n",
            "|16440115|[rt, @justinamash...|(20000,[0,2,14,23...|\n",
            "|16565600|[@atticemphatic, ...|(20000,[97,1683,1...|\n",
            "|16913193|[rt, @charliekirk...|(20000,[0,1,18,66...|\n",
            "|17163957|[@senbobcasey, po...|(20000,[11,333,56...|\n",
            "+--------+--------------------+--------------------+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PgjuCN2x5LJE"
      },
      "source": [
        "\"\"\"\n",
        "Steps: LDA is run to get topic distribution weights\n",
        "\"\"\"\n",
        "num_topics = 40\n",
        "max_iterations = 50\n",
        "lda_model = LDA(k=num_topics, maxIter=max_iterations)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y4GxliIs5gjZ"
      },
      "source": [
        "model = lda_model.fit(df_model)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MXkNVL-f6pUn",
        "outputId": "5afaa657-cedf-4c3b-a762-509808148632"
      },
      "source": [
        "model.describeTopics(10).show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----+--------------------+--------------------+\n",
            "|topic|         termIndices|         termWeights|\n",
            "+-----+--------------------+--------------------+\n",
            "|    0|[250, 384, 457, 3...|[0.01206026249284...|\n",
            "|    1|[71, 300, 606, 88...|[0.01715147394253...|\n",
            "|    2|[438, 619, 1231, ...|[0.02916916995825...|\n",
            "|    3|[633, 1, 727, 715...|[0.01072635970688...|\n",
            "|    4|[189, 289, 549, 9...|[0.01903251228658...|\n",
            "|    5|[152, 243, 465, 4...|[0.01626939361307...|\n",
            "|    6|[379, 387, 313, 1...|[0.01394543821063...|\n",
            "|    7|[326, 337, 430, 8...|[0.01501716037174...|\n",
            "|    8|[224, 262, 81, 9,...|[0.01837542240277...|\n",
            "|    9|[1, 309, 551, 641...|[0.00971620366182...|\n",
            "|   10|[388, 1, 3, 173, ...|[0.00986935010978...|\n",
            "|   11|[46, 366, 36, 341...|[0.02257380707938...|\n",
            "|   12|[546, 637, 554, 1...|[0.01446753421206...|\n",
            "|   13|[533, 813, 1140, ...|[0.02151886025257...|\n",
            "|   14|[217, 296, 437, 9...|[0.01531259964344...|\n",
            "|   15|[495, 282, 1, 759...|[0.01611321619500...|\n",
            "|   16|[1034, 1, 1030, 1...|[0.01157277522048...|\n",
            "|   17|[216, 783, 894, 9...|[0.01916190446919...|\n",
            "|   18|[462, 497, 821, 1...|[0.01993148276281...|\n",
            "|   19|[1, 470, 247, 524...|[0.03196879828116...|\n",
            "+-----+--------------------+--------------------+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vr0aTKJW6pNJ",
        "outputId": "c4cba1fe-ad3e-47e1-d548-57cd55f995ac"
      },
      "source": [
        "transformed = model.transform(df_model)\n",
        "transformed.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------+--------------------+--------------------+--------------------+\n",
            "|      id|            filtered|            features|   topicDistribution|\n",
            "+--------+--------------------+--------------------+--------------------+\n",
            "|  820694|[@jennycohn1, @ro...|(20000,[0,1,10,18...|[1.72724035919036...|\n",
            "| 5385802|[rt, @chrismurphy...|(20000,[0,1,5,40,...|[3.07626862502096...|\n",
            "|12953952|[rt, @magagwen, @...|(20000,[0,1,43,37...|[0.36770541508102...|\n",
            "|13290282|[folks, proven, l...|(20000,[4,205,913...|[3.92306231377565...|\n",
            "|13492362|[rt, @comradezaco...|(20000,[0,32,568,...|[3.90648267384191...|\n",
            "|14060717|[next, week, 2020...|(20000,[92,119,18...|[3.81904868593841...|\n",
            "|14555541|[rt, @kim, @repad...|(20000,[0,1,9,842...|[0.00187650864282...|\n",
            "|14883391|[rt, @4evernevert...|(20000,[0,3,57,13...|[3.41908755665457...|\n",
            "|14884712|[@reptedlieu, kee...|(20000,[37,158,50...|[3.47856130878392...|\n",
            "|15197290|[rt, @kylegriffin...|(20000,[0,223,243...|[2.44218028755828...|\n",
            "|15261298|[rt, @billclarkph...|(20000,[0,25,144,...|[2.87192214508653...|\n",
            "|15416371|[rt, @speakerpelo...|(20000,[0,2,10,19...|[4.51219735524400...|\n",
            "|15541045|                  []|(20000,[1],[1.075...|[0.01250406538403...|\n",
            "|15651137|[rt, @nancypelosi...|(20000,[0,4,23,59...|[3.31224272347425...|\n",
            "|15743275|[rt, @mattduss, c...|(20000,[0,20,47,6...|[1.84418281079596...|\n",
            "|16372633|[rt, @chrismurphy...|(20000,[0,7,17,45...|[0.07746034163468...|\n",
            "|16440115|[rt, @justinamash...|(20000,[0,2,14,23...|[1.77089609189693...|\n",
            "|16565600|[@atticemphatic, ...|(20000,[97,1683,1...|[0.00124158793776...|\n",
            "|16913193|[rt, @charliekirk...|(20000,[0,1,18,66...|[3.55610815513045...|\n",
            "|17163957|[@senbobcasey, po...|(20000,[11,333,56...|[0.12507069443598...|\n",
            "+--------+--------------------+--------------------+--------------------+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oEQjo2bHWueR"
      },
      "source": [
        "For each topic, print out 10 words to describe it"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TQSPGO_FWueR"
      },
      "source": [
        "\"\"\"\n",
        "Steps: each term index is mapped to its respective term weight, and then their weighted value of the word is chosen to represent in the 'Topic Descriptions' column\n",
        "\"\"\"\n",
        "vocab = cvmodel.vocabulary\n",
        "vocab_broadcast = sc.broadcast(vocab)\n",
        "ldatopics = model.describeTopics(10)\n",
        "\n",
        "def map_termID_to_word(termIndices):\n",
        "  words = []\n",
        "  for termID in termIndices:\n",
        "    words.append(vocab_broadcast.value[termID])\n",
        "  return words\n",
        "\n",
        "udf_map_termID_to_Word = udf(map_termID_to_word, ArrayType(StringType()))\n",
        "\n",
        "ldatopics_mapped = ldatopics.withColumn(\"Topic Descriptions\", udf_map_termID_to_Word(ldatopics.termIndices))\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jObUGBwkfBWR",
        "outputId": "f145ecd1-3c18-4daf-b63d-3b24a1b596a5"
      },
      "source": [
        "#ANSWER\n",
        "### TOPIC DESCRIPTIONS TO THE RIGHT OF THE TABLE ----->>>>>>###\n",
        "ldatopics_mapped.show(41, False)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----+---------------------------------------------------------+-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+-----------------------------------------------------------------------------------------------------------------------------+\n",
            "|topic|termIndices                                              |termWeights                                                                                                                                                                                                                    |Topic Descriptions                                                                                                           |\n",
            "+-----+---------------------------------------------------------+-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+-----------------------------------------------------------------------------------------------------------------------------+\n",
            "|0    |[250, 384, 457, 34, 193, 412, 184, 195, 699, 256]        |[0.012060262492845019, 0.008924847288415484, 0.00877150017318805, 0.007782882420711827, 0.007740281434401651, 0.007726223681126828, 0.007593367685030225, 0.007321069341072889, 0.007051226183987697, 0.006865897902285282]    |[evidence, immigration, @saracarterdc, border, illegal, laws, @senblumenthal, crisis, information, ag]                       |\n",
            "|1    |[71, 300, 606, 887, 15, 375, 323, 734, 800, 1344]        |[0.017151473942537625, 0.010377626444411037, 0.009926152646959863, 0.009761178025544416, 0.009732066538953707, 0.009036241551022006, 0.008992718442832887, 0.008443729251416612, 0.008299889485391506, 0.007337062640061656]   |[@repmattgaetz, tweet, former, james, @jimjordan, @cnn, collusion, @timkaine, order, mccabe]                                 |\n",
            "|2    |[438, 619, 1231, 899, 1578, 1965, 1668, 1943, 1728, 188] |[0.029169169958252635, 0.013711596379434112, 0.011193780242571763, 0.01049487026135201, 0.008524841579714327, 0.007954815949722598, 0.007835771553515981, 0.007382053168779907, 0.007160881888089785, 0.007135324004025286]    |[fuck, washington, fired, tells, girl, gas, obviously, @royblunt, chose, impeachment]                                        |\n",
            "|3    |[633, 1, 727, 715, 934, 317, 831, 1210, 1381, 1238]      |[0.01072635970688838, 0.009546690481669296, 0.009415016426681917, 0.009182066657143655, 0.006723959942934036, 0.006510551790271624, 0.0063408105406278364, 0.0056494740924761516, 0.005623280648461126, 0.005456913440786443]  |[@clairecmc, , @senorrinhatch, hours, @fbi, sen, happening, broken, march, represent]                                        |\n",
            "|4    |[189, 289, 549, 985, 990, 1, 1108, 402, 1150, 1338]      |[0.019032512286589275, 0.01869752837962101, 0.012033681156952997, 0.00818269832946776, 0.00814316770534376, 0.008040985980231768, 0.007767192599570894, 0.0070484849871819515, 0.006625787266953696, 0.006603382842399892]     |[year, old, held, disgrace, citizen, , 13, resign, veterans, mother]                                                         |\n",
            "|5    |[152, 243, 465, 489, 1080, 12, 97, 982, 1017, 113]       |[0.016269393613078064, 0.013085647617200479, 0.011085569668953976, 0.007551800936713853, 0.007079138008690403, 0.007029183449509479, 0.006857239779906917, 0.006645213800910294, 0.006585046710621575, 0.00614683177370781]    |[tax, war, saudi, speak, yemen, us, @chrismurphyct, arabia, @senrobportman, white]                                           |\n",
            "|6    |[379, 387, 313, 1, 400, 709, 844, 475, 1240, 612]        |[0.01394543821063833, 0.013550216541214051, 0.013318194159952272, 0.012366134188699057, 0.009393120105675813, 0.008669045687406233, 0.006690380936779949, 0.006095658433588407, 0.006094182718615376, 0.005808705442388812]    |[lindsey, graham, part, , mean, hillary, course, heard, joe, investigate]                                                    |\n",
            "|7    |[326, 337, 430, 80, 662, 721, 1, 918, 360, 1072]         |[0.015017160371741339, 0.013138999981937348, 0.012903418942251978, 0.010203636064210165, 0.009038038161360425, 0.008682878725995543, 0.007491980000564171, 0.005743127377450856, 0.00546098993592812, 0.005098368584934629]    |[@ilhanmn, @rokhanna, moscowmitch, @aoc, @rashidatlaib, @repbarbaralee, , total, lies, attempt]                              |\n",
            "|8    |[224, 262, 81, 9, 1, 856, 523, 1167, 0, 1098]            |[0.018375422402777463, 0.018130458850647176, 0.00739157203143349, 0.006779102745686985, 0.006702734382565449, 0.006103695466609913, 0.006026285062705225, 0.005691779310631337, 0.00555475415179991, 0.0055034117209555545]    |[general, attorney, barr, @repadamschiff, , fire, @tribelaw, count, rt, @senrickscott]                                       |\n",
            "|9    |[1, 309, 551, 641, 120, 357, 1042, 740, 781, 0]          |[0.00971620366182262, 0.007989684722194215, 0.007428517251437038, 0.006918278958993731, 0.006363922565686416, 0.005637400069027743, 0.005260754893614769, 0.005085697665652209, 0.005077941245497215, 0.004582298239283226]    |[, free, name, voters, women, lie, @thehill, comes, presidential, rt]                                                        |\n",
            "|10   |[388, 1, 3, 173, 536, 902, 0, 274, 1107, 9]              |[0.009869350109783804, 0.00932126835688296, 0.008137578112334115, 0.006556301136043088, 0.006275169569327524, 0.005840062351726565, 0.005471032956914968, 0.005014619151651012, 0.00497183480409505, 0.004915952529825958]     |[god, , trump, russia, wasnt, russians, rt, anything, seeing, @repadamschiff]                                                |\n",
            "|11   |[46, 366, 36, 341, 258, 485, 1, 815, 857, 625]           |[0.022573807079388712, 0.018473336495637017, 0.011019541458891375, 0.010133478530359584, 0.009841918722837467, 0.009110809897362364, 0.008745236346128202, 0.008112716449840547, 0.00714082802915004, 0.0069201753503892564]   |[@repjerrynadler, @housejudiciary, mueller, letter, special, counsel, , robert, testify, tomorrow]                           |\n",
            "|12   |[546, 637, 554, 1089, 1046, 1133, 1, 1468, 890, 924]     |[0.014467534212067984, 0.012509555308098847, 0.01210235104714367, 0.008323003603302187, 0.008272645833437004, 0.008079685616872338, 0.007047736334629834, 0.006962961384700375, 0.006959000035188496, 0.00695845347100185]     |[cohen, michael, seems, @replouiegohmert, correct, agreed, , minister, sign, accused]                                        |\n",
            "|13   |[533, 813, 1140, 1214, 1022, 731, 828, 615, 977, 1213]   |[0.02151886025257033, 0.014353348397209819, 0.011402770655374324, 0.011155458258775364, 0.01078644398820759, 0.009584939109966436, 0.009470709542704521, 0.00913380199412932, 0.008991539136005857, 0.008619451204315044]      |[bernie, afraid, sanders, consider, fear, @senatormenendez, race, press, truly, conference]                                  |\n",
            "|14   |[217, 296, 437, 987, 9, 754, 1245, 1118, 683, 390]       |[0.01531259964344557, 0.013426655788999035, 0.011113578661863431, 0.008614424609291089, 0.008494723935085569, 0.007429976633596303, 0.00645942671386618, 0.0063980781765896454, 0.006255162431093107, 0.006095987136003773]    |[change, climate, impeach, courage, @repadamschiff, mind, sounds, fo, save, taking]                                          |\n",
            "|15   |[495, 282, 1, 759, 6, 943, 768, 1059, 1026, 1162]        |[0.016113216195002156, 0.014701032169171197, 0.013294124759978966, 0.012078637727361972, 0.010163343502280408, 0.010057102614385761, 0.009710809359147681, 0.00815655123374556, 0.007380064255043447, 0.007182786484436555]    |[@seanhannity, @foxnews, , soon, @lindseygrahamsc, @ingrahamangle, waiting, comment, @marshablackburn, regime]               |\n",
            "|16   |[1034, 1, 1030, 1259, 1342, 1385, 264, 1398, 1722, 1729] |[0.011572775220483734, 0.011108998639105935, 0.009441721690533323, 0.009084054973234215, 0.008683400704333587, 0.00807904227629598, 0.007880091923152222, 0.00787070988737262, 0.007669095577875265, 0.007570781836015384]     |[class, , middle, treason, urge, research, 2020, fine, fan, cosponsor]                                                       |\n",
            "|17   |[216, 783, 894, 960, 519, 209, 845, 16, 846, 1320]       |[0.01916190446919931, 0.013686285666958802, 0.011531580511098746, 0.011011087328691613, 0.010473353258147, 0.010020237334885381, 0.008782152741529194, 0.008468166845190299, 0.008150943304748212, 0.007807667043643813]       |[u, telling, racism, gonna, looks, truth, @dbongino, like, sir, dumb]                                                        |\n",
            "|18   |[462, 497, 821, 1053, 810, 1324, 2169, 1356, 1121, 1652] |[0.019931482762812886, 0.017478663756694143, 0.01647637772742565, 0.011923296606638297, 0.009653554682279346, 0.009304088792389165, 0.009279511398752835, 0.007770871656488286, 0.007646092518952918, 0.007031481321061515]    |[@, @realjameswoods, @senatorburr, cc, confirmed, deserves, blah, guard, nominee, warren]                                    |\n",
            "|19   |[1, 470, 247, 524, 49, 2, 133, 6, 988, 0]                |[0.03196879828116232, 0.00936563828255782, 0.008131170056938223, 0.007425804703565335, 0.007277056539586678, 0.0061728559105511055, 0.00603116206494083, 0.005922487817131267, 0.005269600981267354, 0.005248457184355063]     |[, @whitehouse, called, stupid, @gopleader, @realdonaldtrump, party, @lindseygrahamsc, term, rt]                             |\n",
            "|20   |[732, 594, 32, 922, 1317, 598, 1515, 1347, 1881, 2126]   |[0.018919887225968286, 0.01807918975663532, 0.01248167413739244, 0.010160075396066576, 0.009693497038870515, 0.00868912850043446, 0.00839720048613872, 0.007563936044152295, 0.0072600181122453285, 0.0070957033656831705]     |[@repthomasmassie, @pattymurray, transport, along, fool, secretary, il, @washingtonpost, @dwstweets, communist]              |\n",
            "|21   |[132, 62, 213, 378, 1, 682, 566, 955, 474, 109]          |[0.021349450960115427, 0.02022051414154884, 0.012645766178087721, 0.011419228826450235, 0.008505319017544817, 0.007846909425457937, 0.007238613458013343, 0.006750123673624152, 0.00671498853257781, 0.006590365175992819]     |[@jeffflake, @senatorcollins, @lisamurkowski, live, , @senjoemanchin, @davidcicilline, rich, lot, well]                      |\n",
            "|22   |[514, 1, 252, 592, 880, 436, 1054, 136, 1484, 1005]      |[0.010566507464371037, 0.00994596184527497, 0.009542884415019322, 0.0092128679760494, 0.00796454198090732, 0.007818753167609471, 0.007332669855318243, 0.00720182623607823, 0.00584153376914313, 0.005716818707890616]         |[cut, , million, medicare, budget, @joaquincastrotx, rather, @justinamash, trip, possible]                                   |\n",
            "|23   |[393, 898, 1124, 773, 1180, 1274, 1288, 1292, 113, 1527] |[0.01533938355597839, 0.008934607556961446, 0.0076366056523793375, 0.0074048552173925615, 0.007234999499711227, 0.00711988198873834, 0.006504241929040544, 0.0064372636740437, 0.006240991991906793, 0.006068718648603102]     |[problem, hands, @presssec, americas, playing, father, @repspeier, fully, white, peoples]                                    |\n",
            "|24   |[239, 444, 724, 573, 667, 1, 823, 1144, 1003, 3]         |[0.011525610574412745, 0.01048507645638503, 0.009617779499663734, 0.009436171229196351, 0.009079650741686667, 0.008030639402662796, 0.006975983272310645, 0.00680198273639409, 0.006696324850738598, 0.006234187752813608]     |[shut, fake, schumer, chuck, couldnt, , prison, @nytimes, worth, trump]                                                      |\n",
            "|25   |[698, 550, 970, 369, 588, 3, 1073, 748, 1172, 1656]      |[0.012950559721148088, 0.010227269587379718, 0.010191526594843778, 0.008587900549093247, 0.00830212396418135, 0.008203441512504184, 0.0076957061010283325, 0.007501959848765245, 0.007364664661894543, 0.007300970692689287]   |[lol, story, whitaker, criminal, fraud, trump, hasnt, given, trade, emails]                                                  |\n",
            "|26   |[50, 34, 218, 407, 319, 513, 1, 267, 2, 336]             |[0.023263215744937827, 0.014925720078477428, 0.011621465151619563, 0.010370349625362388, 0.010142730713261735, 0.009229467538387246, 0.009223196588547495, 0.007715302146385109, 0.006769104132941581, 0.00664238814495913]    |[wall, border, better, build, emergency, mexico, , court, @realdonaldtrump, home]                                            |\n",
            "|27   |[1, 10, 8, 82, 2, 351, 96, 78, 281, 726]                 |[0.02043685921348105, 0.014628350619260693, 0.013311827863929877, 0.011296696858317188, 0.009599860979435732, 0.009009190366107313, 0.008808042126971673, 0.006978416049849455, 0.006696280830671699, 0.006484238246695103]    |[, @speakerpelosi, @senschumer, @nancypelosi, @realdonaldtrump, nancy, @repmaxinewaters, @senfeinstein, pelosi, @barackobama]|\n",
            "|28   |[168, 211, 333, 1, 632, 499, 700, 1056, 691, 640]        |[0.01707225563318329, 0.01599304340913521, 0.015885856522558115, 0.010535411909687155, 0.008820807490397115, 0.007591457958645112, 0.007306892722379731, 0.007157875672132151, 0.006885773159705717, 0.006723212351075144]     |[states, united, hate, , calls, friend, listen, whos, force, maga]                                                           |\n",
            "|29   |[201, 1, 526, 4, 0, 25, 99, 32, 244, 324]                |[0.008965088763714593, 0.00861126018269151, 0.008340049636804202, 0.007270618297978189, 0.006031042614865212, 0.005866249855769044, 0.005476252778556683, 0.005401208677034474, 0.005222820097453883, 0.004951194809291839]    |[health, , mass, amp, rt, @sensanders, care, transport, military, democracy]                                                 |\n",
            "|30   |[31, 88, 13, 131, 145, 118, 148, 315, 174, 392]          |[0.040776347779663075, 0.025694775715450823, 0.02262393312239348, 0.020614294104473473, 0.019258751003429254, 0.01887330963368399, 0.017456169101627075, 0.012254957465988012, 0.011095035324108514, 0.010669587784575003]     |[de, la, @marcorubio, en, que, el, y, los, venezuela, le]                                                                    |\n",
            "|31   |[389, 803, 1, 684, 997, 1130, 629, 365, 480, 1043]       |[0.01097374509511523, 0.008057252396894674, 0.007977866819847948, 0.007035775620188981, 0.006871177600871174, 0.006507749459070773, 0.006126022487013203, 0.00597457667873156, 0.005949799118143745, 0.005750686730161682]     |[talking, candidate, , id, especially, small, @repjohnlewis, hard, shes, @sensherrodbrown]                                   |\n",
            "|32   |[868, 340, 1082, 774, 1401, 1309, 1630, 1425, 1575, 1294]|[0.012455724064766171, 0.011590973103655235, 0.010135014987201641, 0.009842850216593672, 0.008787115711806839, 0.00828709587480016, 0.008083289863034589, 0.008078507226695699, 0.00807091464398024, 0.007743847388588447]     |[china, point, destroy, tweets, ne, @stevedaines, dude, matt, @mattgaetz, students]                                          |\n",
            "|33   |[149, 175, 327, 1, 737, 56, 531, 953, 368, 278]          |[0.01352667604200788, 0.010776782797255547, 0.01063653844952845, 0.010067939266509549, 0.006517811293871031, 0.006377346408187784, 0.006134740707780836, 0.005971877537516705, 0.0058401645763113, 0.0056697819303521664]      |[yes, sure, rights, , line, make, answer, nice, human, voting]                                                               |\n",
            "|34   |[1, 5, 2, 70, 14, 99, 0, 29, 6, 344]                     |[0.013081375859901389, 0.01027842397380821, 0.00836158024515248, 0.008212640637122457, 0.007048305771065054, 0.006501233135737881, 0.005619715382738111, 0.005519580288251486, 0.005242417356349184, 0.0052364554092834414]    |[, @senatemajldr, @realdonaldtrump, @gop, dont, care, rt, vote, @lindseygrahamsc, little]                                    |\n",
            "|35   |[188, 763, 435, 79, 1, 1007, 941, 666, 597, 165]         |[0.007879549412229974, 0.007767898411410682, 0.007641798031734532, 0.007193006296474224, 0.0063441025280022495, 0.006296080281251979, 0.006199506947032745, 0.006197363551498127, 0.0058569358612712225, 0.0058168167112459005]|[impeachment, amendment, control, day, , inquiry, blocking, died, future, gun]                                               |\n",
            "|36   |[19, 28, 1, 63, 5, 0, 91, 203, 29, 84]                   |[0.011444667491112132, 0.01121081836619168, 0.010235792397205654, 0.00881208357030806, 0.0075949784172388264, 0.007518008676818664, 0.007067774597632869, 0.006541510140409667, 0.006457009582703027, 0.006243417836654989]    |[house, senate, , bill, @senatemajldr, rt, mcconnell, passed, vote, @senategop]                                              |\n",
            "|37   |[116, 529, 108, 503, 1, 1147, 1283, 1197, 1230, 1549]    |[0.023179175071547306, 0.012304090674054621, 0.01195072844806094, 0.011919577286158892, 0.010298068236865309, 0.007568626621156729, 0.0070970237134348356, 0.006748295137222616, 0.006665759144350478, 0.005924033042386642]   |[@johncornyn, @tedcruz, @chuckgrassley, @senmikelee, , sit, south, @bensasse, happens, awesome]                              |\n",
            "|38   |[228, 95, 1, 556, 601, 670, 226, 679, 66, 745]           |[0.011463057742863414, 0.010830047083582345, 0.009433851299408175, 0.008728302091439854, 0.008639271939845872, 0.008344300847229867, 0.007820721301105501, 0.00730984906947433, 0.006979461517618976, 0.0058121137824398246]   |[enough, @sengillibrand, , @ewarren, shame, @joebiden, @kamalaharris, idiot, @corybooker, @betoorourke]                      |\n",
            "|39   |[165, 542, 458, 855, 951, 1193, 767, 1380, 1450, 1308]   |[0.011770565784193127, 0.01151344575236245, 0.009755939323146248, 0.009167237346391655, 0.007965974654392687, 0.007574923464818166, 0.0070904275492104495, 0.0067393900744557025, 0.0066505152248745635, 0.0064941636504155945]|[gun, check, system, buy, @repdonbeyer, bullshit, kill, nancypelosi, write, presidency]                                      |\n",
            "+-----+---------------------------------------------------------+-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+-----------------------------------------------------------------------------------------------------------------------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qW_ihPOlWuef"
      },
      "source": [
        "## (45 points) Part 3: Community Detection\n",
        "User-hashtag relations have been extracted and saved in the file `us-congress-tweets/user_hashtags-1m.csv`. If a user uses a hashtag there will be a record with the userid and the hashtag.\n",
        "\n",
        "For community detection we will implement the Trawling algorithm based on frequent itemset mining using [FPGrowth](https://spark.apache.org/docs/2.3.0/ml-frequent-pattern-mining.html) to find potential user communities in the dataset. FPGrowth is like apriori as discussed in class, but operates a bit differently. Although we don't need to completely understand the algorithm for this assignment, feel free to explore on your own! Explore different values for the support parameter, and report your results in the cells below.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HpE-rwOQWuef"
      },
      "source": [
        "# your code here. Explain all steps.\n",
        "from pyspark.ml.fpm import FPGrowth\n",
        "df = spark.read.csv(\"us-congress-tweets/user_hashtags-1m.csv\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UbfFw7pisw7v",
        "outputId": "727ab187-c641-4ee2-a3c1-24ba00c7519a"
      },
      "source": [
        "\"\"\"\n",
        "Steps:\n",
        "1) to do something like the opposite of an explode function, I merged the hashtags that had the same IDs as sets\n",
        "2) FPGrowth algorithm is run with low min support to get itemset relations\n",
        "\"\"\"\n",
        "grouped_hashtags = df.groupBy('_c0').agg(collect_set('_c1').alias('hashtags'))\n",
        "grouped_hashtags.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-------------------+--------------------+\n",
            "|                _c0|            hashtags|\n",
            "+-------------------+--------------------+\n",
            "|1002338860162936832|[ThankGod, Democr...|\n",
            "|1002752931341299712|[impeach, POTUS, ...|\n",
            "|1003231727643496448|[BelieveWomen, My...|\n",
            "|1004434675044057088|        [DeportOmar]|\n",
            "|1004865478274244610|       [MoscowMitch]|\n",
            "|1006268755058577408|   [WAECCertificate]|\n",
            "|1007154784430968834|[Chavista, MAGAve...|\n",
            "|           10073222|          [RandPaul]|\n",
            "|1007386606217637888|[116thCongress, B...|\n",
            "|         1007629891|     [TrumpShutdown]|\n",
            "|1008731226281332736|[WithoutWomenMenW...|\n",
            "|1008765038432096256|      [Tech, Cities]|\n",
            "|1009406348222717952|         [Kavanaugh]|\n",
            "|          100973954|[WestBaltimore, R...|\n",
            "|1009786407030845440|          [midterms]|\n",
            "|1009829347476287493|[DCIranFreedomMarch]|\n",
            "|1009830390767505409|[EndTheShutdown, ...|\n",
            "|1011299850296717312|          [Axios360]|\n",
            "|1011778525093867520|        [Newsmakers]|\n",
            "|1012339433541160966|                [UN]|\n",
            "+-------------------+--------------------+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aamDmW5S2W5M"
      },
      "source": [
        "fpgrowth = FPGrowth(itemsCol='hashtags', minSupport=0.0001)\n",
        "model = fpgrowth.fit(grouped_hashtags)\n",
        "frequent_hashtags = model.freqItemsets.orderBy(desc('freq'))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gOh7i1qz3HMT",
        "outputId": "08f96613-1534-45e2-a107-eb9a7500a026"
      },
      "source": [
        "frequent_hashtags.filter(size('items') == 2).show(20, False)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+------------------------------+----+\n",
            "|items                         |freq|\n",
            "+------------------------------+----+\n",
            "|[MaduroRegime, Venezuela]     |93  |\n",
            "|[TrumpShutdown, MuellerReport]|83  |\n",
            "|[NancyPelosi, MAGA]           |76  |\n",
            "|[BREAKING, MuellerReport]     |63  |\n",
            "|[Trump, NancyPelosi]          |63  |\n",
            "|[TrumpShutdown, MoscowMitch]  |63  |\n",
            "|[MuellerReport, MoscowMitch]  |63  |\n",
            "|[MAGA, MuellerReport]         |62  |\n",
            "|[ForThePeople, TrumpShutdown] |61  |\n",
            "|[Kavanaugh, MAGA]             |61  |\n",
            "|[Kavanaugh, MuellerReport]    |60  |\n",
            "|[Mueller, MuellerReport]      |60  |\n",
            "|[ForThePeople, MuellerReport] |59  |\n",
            "|[Trump, MuellerReport]        |58  |\n",
            "|[HR1, MuellerReport]          |56  |\n",
            "|[BuildTheWall, MAGA]          |56  |\n",
            "|[BREAKING, MoscowMitch]       |56  |\n",
            "|[NancyPelosi, MuellerReport]  |55  |\n",
            "|[Democrats, NancyPelosi]      |54  |\n",
            "|[Maduro, MaduroRegime]        |54  |\n",
            "+------------------------------+----+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "brHYE-0VOKGL",
        "outputId": "c98e5c1a-5c03-4fe1-8243-fafc6e647e80"
      },
      "source": [
        "frequent_hashtags.filter(size('items') == 3).show(20, False)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----+----+\n",
            "|items|freq|\n",
            "+-----+----+\n",
            "+-----+----+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hqsRqjIKWueg"
      },
      "source": [
        "List two user communities you think are interesting. Explain why they are reasonable communities.\n",
        "\n",
        "You can use https://twitter.com/intent/user?user_id=? to find out more info about the users"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iO-PtyoDR0aI"
      },
      "source": [
        "[BuildTheWall, MAGA] -> 56 frequency: Reasonable hashtags together given that most #MAGA supportors also support #BuildTheWall which was one of Trump's failed promises."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BVg6tGyIR09d"
      },
      "source": [
        "[TrumpShutdown, MuellerReport] -> 83 frequency: Reasonable hashtags together given that Robert Mueller released a report stating that the Trump campaign and Russia worked together. Both tweets emerged when the report went public and people wanted Trump to get impeached."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8bTo_EkZWueh"
      },
      "source": [
        "What value for support did you choose and why?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jyLJbCTh88AA"
      },
      "source": [
        "The objective to picking an optimum support is that it's low enough to obtain some frequent itemsets that have k>=2 but not too low that the itemsets occurred by chance (random/useless information). I tested minsup = 0.1, 0.01, and 0.001 which were too high and did not produce any itemsets. I tested minsup = 0.0001 which produced multiple k=2 itemsets and settled on this. I also tested minsup = 0.00001 which produced a k=3 itemset but this support felt like it produced some random itemsets."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ha2vrLOmWueh"
      },
      "source": [
        "## (20 points) Part 4: Personalized PageRank\n",
        "Assume you are given a task to recommend Twitter users for the speaker of the House to engage with.\n",
        "\n",
        "Construct a user-mentions network using relations in `us-congress-tweets/user_mentions.csv`\n",
        "\n",
        "Run Personalized PageRank with source (id=15764644) and find out top 10 accounts to recommend."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GMfDE2utPbFR"
      },
      "source": [
        "from graphframes import *\n",
        "from pyspark.sql.functions import *\n",
        "from pyspark.sql import SQLContext"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c1HwmZJCWueh"
      },
      "source": [
        "# your network construction code here\n",
        "\"\"\"\n",
        "Steps:\n",
        "1) e = the entire user mentions csv as is, but with minor modifications, like changing them to longtype and removing empty rows\n",
        "2) v = merged set of src and dst as id\n",
        "3) GraphFrame constructs the network\n",
        "\"\"\"\n",
        "e = spark.read.csv(\"us-congress-tweets/user_mentions.csv\", header=True)\n",
        "e = e.withColumn(\"src\", e[\"src\"].cast(LongType()))\n",
        "e = e.withColumn(\"dst\", e[\"dst\"].cast(LongType()))\n",
        "e = e.withColumn(\"count\", e[\"count\"].cast(LongType()))\n",
        "e = e.dropna()\n",
        "\n",
        "v = e.select(col(\"src\").alias(\"id\")).union(e.select(col(\"dst\").alias(\"id\"))).distinct()\n",
        "\n",
        "# v = e.select(explode(array('src', 'dst')).alias('id')).distinct().dropna()\n",
        "# v = v.withColumn(\"id\", v[\"id\"].cast(LongType()))\n",
        "\n",
        "g = GraphFrame(v, e)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YHgs08vfWuei"
      },
      "source": [
        "# your Personalized PageRank code here\n",
        "results = g.pageRank(sourceId=15764644, maxIter=5, resetProbability=0.15)\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CVYfXMDMWuei",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "30b39211-e7ad-40d4-f68e-6005473c57e5"
      },
      "source": [
        "# Top 10 accounts to recommend \n",
        "# You can use https://twitter.com/intent/user?user_id=? to find out more info about the users\n",
        "results.vertices.select('id', 'pagerank').orderBy(desc('pagerank')).show(11)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-------------------+--------------------+\n",
            "|                 id|            pagerank|\n",
            "+-------------------+--------------------+\n",
            "|           15764644|  0.4552197044272686|\n",
            "|          199325935| 0.12897891625439276|\n",
            "|         1092979962| 0.12897891625439276|\n",
            "|          381152398| 0.12897891625439276|\n",
            "|         1487846678|0.012181342090692647|\n",
            "|          131208075|0.012181342090692647|\n",
            "|           43963249|0.012181342090692647|\n",
            "|           10613072|0.012181342090692647|\n",
            "|           30912937|0.012181342090692647|\n",
            "|           60618211|0.012181342090692647|\n",
            "|1080198683713507335|0.012181342090692647|\n",
            "+-------------------+--------------------+\n",
            "only showing top 11 rows\n",
            "\n"
          ]
        }
      ]
    }
  ]
}